import requests
from bs4 import BeautifulSoup
import os
import json
import re
import time
path =r'./ltn_RSS/%s'
if not os.path.exists(r'./ltn_RSS'):
    os.mkdir(r'./ltn_RSS')
rss = 'https://news.ltn.com.tw/rss/business.xml'
headers={'user-agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/80.0.3987.106 Safari/537.36'}
session = requests.session()
response = session.get(rss, headers = headers)
soup = BeautifulSoup(response.text, 'html.parser')
session.close()
for n in range(len(soup.select('item'))):
    title = soup.select('item')[n].title.text.replace('/','_').replace('<','_').replace('>','_').replace('\\','_').replace('ï¼ƒ','_').replace('?','_').replace("\r",'_').replace("\n",'_')
    if os.path.exists(path % (title)+ '.json'):
        break
    else:
        date = soup.select('item')[n].pubdate.text
        clicks = "NA"
        tag = "NA"
        content_text = ''
        content_url =re.search(r'https://news.ltn.com.tw/news/business/breakingnews/(\d)+',soup.select('item')[n].text)[0]
        response_content = session.get(content_url, headers=headers)
        content_soup = BeautifulSoup(response_content.text, 'html.parser')
        for j in content_soup.select('p'):
            if len(j.text) > 2:
                content_text += j.text
        content_text = content_text.split('\n')[0]
        output = {'date': date, 'title': title, 'content': content_text, 'href': content_url, 'tag': tag, 'clicks': clicks}
        with open(path % (title) + '.json', 'w', encoding='utf8') as f:
            json.dump(output, f)
        time.sleep(3)    
session.close()
